{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_tree.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOFuxqcyFbYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from future.utils import iteritems\n",
        "\n",
        "import numpy as np\n",
        "#from util import get_data, get_xor, get_donut\n",
        "from datetime import datetime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSFaKK1c22I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entropy(y):\n",
        "    # assume y is binary - 0 or 1\n",
        "    N = len(y)\n",
        "    s1 = (y == 1).sum()\n",
        "    if 0 == s1 or N == s1:\n",
        "        return 0\n",
        "    p1 = float(s1) / N\n",
        "    p0 = 1 - p1\n",
        "    return -p0*np.log2(p0) - p1*np.log2(p1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUrDnuMfU_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, depth=1, max_depth=None):\n",
        "        print('depth:', depth)\n",
        "        self.depth = depth\n",
        "        self.max_depth = max_depth\n",
        "        if self.max_depth is not None and self.max_depth < self.depth:\n",
        "            raise Exception(\"depth > max_depth\")\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        if len(Y) == 1 or len(set(Y)) == 1:\n",
        "            # base case, only 1 sample\n",
        "            # another base case\n",
        "            # this node only receives examples from 1 class\n",
        "            # we can't make a split\n",
        "            self.col = None\n",
        "            self.split = None\n",
        "            self.left = None\n",
        "            self.right = None\n",
        "            self.prediction = Y[0]\n",
        "\n",
        "        else:\n",
        "            D = X.shape[1]\n",
        "            cols = range(D)\n",
        "\n",
        "            max_ig = 0\n",
        "            best_col = None\n",
        "            best_split = None\n",
        "            for col in cols:\n",
        "                ig, split = self.find_split(X, Y, col)\n",
        "                # print \"ig:\", ig\n",
        "                if ig > max_ig:\n",
        "                    max_ig = ig\n",
        "                    best_col = col\n",
        "                    best_split = split\n",
        "\n",
        "            if max_ig == 0:\n",
        "                # nothing we can do\n",
        "                # no further splits\n",
        "                self.col = None\n",
        "                self.split = None\n",
        "                self.left = None\n",
        "                self.right = None\n",
        "                self.prediction = np.round(Y.mean())\n",
        "            else:\n",
        "                self.col = best_col\n",
        "                self.split = best_split\n",
        "\n",
        "                if self.depth == self.max_depth:\n",
        "                    self.left = None\n",
        "                    self.right = None\n",
        "                    self.prediction = [\n",
        "                        np.round(Y[X[:,best_col] < self.split].mean()),\n",
        "                        np.round(Y[X[:,best_col] >= self.split].mean()),\n",
        "                    ]\n",
        "                else:\n",
        "                    # print \"best split:\", best_split\n",
        "                    left_idx = (X[:,best_col] < best_split)\n",
        "                    # print \"left_idx.shape:\", left_idx.shape, \"len(X):\", len(X)\n",
        "                    Xleft = X[left_idx]\n",
        "                    Yleft = Y[left_idx]\n",
        "                    self.left = TreeNode(self.depth + 1, self.max_depth)\n",
        "                    self.left.fit(Xleft, Yleft)\n",
        "\n",
        "                    right_idx = (X[:,best_col] >= best_split)\n",
        "                    Xright = X[right_idx]\n",
        "                    Yright = Y[right_idx]\n",
        "                    self.right = TreeNode(self.depth + 1, self.max_depth)\n",
        "                    self.right.fit(Xright, Yright)\n",
        "\n",
        "    def find_split(self, X, Y, col):\n",
        "        # print \"finding split for col:\", col\n",
        "        x_values = X[:, col]\n",
        "        sort_idx = np.argsort(x_values)\n",
        "        x_values = x_values[sort_idx]\n",
        "        y_values = Y[sort_idx]\n",
        "\n",
        "        # Note: optimal split is the midpoint between 2 points\n",
        "        # Note: optimal split is only on the boundaries between 2 classes\n",
        "\n",
        "        # if boundaries[i] is true\n",
        "        # then y_values[i] != y_values[i+1]\n",
        "        # nonzero() gives us indices where arg is true\n",
        "        # but for some reason it returns a tuple of size 1\n",
        "        boundaries = np.nonzero(y_values[:-1] != y_values[1:])[0]\n",
        "        best_split = None\n",
        "        max_ig = 0\n",
        "        for b in boundaries:\n",
        "            split = (x_values[b] + x_values[b+1]) / 2\n",
        "            ig = self.information_gain(x_values, y_values, split)\n",
        "            if ig > max_ig:\n",
        "                max_ig = ig\n",
        "                best_split = split\n",
        "        return max_ig, best_split\n",
        "\n",
        "    def information_gain(self, x, y, split):\n",
        "        # assume classes are 0 and 1\n",
        "        # print \"split:\", split\n",
        "        y0 = y[x < split]\n",
        "        y1 = y[x >= split]\n",
        "        N = len(y)\n",
        "        y0len = len(y0)\n",
        "        if y0len == 0 or y0len == N:\n",
        "            return 0\n",
        "        p0 = float(len(y0)) / N\n",
        "        p1 = 1 - p0 #float(len(y1)) / N\n",
        "        # print \"entropy(y):\", entropy(y)\n",
        "        # print \"p0:\", p0\n",
        "        # print \"entropy(y0):\", entropy(y0)\n",
        "        # print \"p1:\", p1\n",
        "        # print \"entropy(y1):\", entropy(y1)\n",
        "        return entropy(y) - p0*entropy(y0) - p1*entropy(y1)\n",
        "\n",
        "    def predict_one(self, x):\n",
        "        # use \"is not None\" because 0 means False\n",
        "        if self.col is not None and self.split is not None:\n",
        "            feature = x[self.col]\n",
        "            if feature < self.split:\n",
        "                if self.left:\n",
        "                    p = self.left.predict_one(x)\n",
        "                else:\n",
        "                    p = self.prediction[0]\n",
        "            else:\n",
        "                if self.right:\n",
        "                    p = self.right.predict_one(x)\n",
        "                else:\n",
        "                    p = self.prediction[1]\n",
        "        else:\n",
        "            # corresponds to having only 1 prediction\n",
        "            p = self.prediction\n",
        "        return p\n",
        "\n",
        "    def predict(self, X):\n",
        "        N = len(X)\n",
        "        P = np.zeros(N)\n",
        "        for i in range(N):\n",
        "            P[i] = self.predict_one(X[i])\n",
        "        return P"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF6BfC3ZfbSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.root = TreeNode(max_depth=self.max_depth)\n",
        "        self.root.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.root.predict(X)\n",
        "\n",
        "    def score(self, X, Y):\n",
        "        P = self.predict(X)\n",
        "        return np.mean(P == Y)\n",
        "\n",
        "def get_data(limit=None):\n",
        "    print(\"Reading in and transforming data...\")\n",
        "    df = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "    data = df.values\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, 1:] / 255.0 # data is from 0..255\n",
        "    Y = data[:, 0]\n",
        "    if limit is not None:\n",
        "        X, Y = X[:limit], Y[:limit]\n",
        "    return X, Y\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUCV8rgtffNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "34b5b9ca-1a5b-48a8-af19-658eadb2daff"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    X, Y = get_data()\n",
        "\n",
        "    # try donut and xor\n",
        "    # from sklearn.utils import shuffle\n",
        "    # X, Y = get_xor()\n",
        "    # # X, Y = get_donut()\n",
        "    # X, Y = shuffle(X, Y)\n",
        "\n",
        "    # only take 0s and 1s since we're doing binary classification\n",
        "    idx = np.logical_or(Y == 0, Y == 1)\n",
        "    X = X[idx]\n",
        "    Y = Y[idx]\n",
        "\n",
        "    # split the data\n",
        "    Ntrain = len(Y) // 2\n",
        "    Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
        "    Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
        "    \n",
        "    model = DecisionTree()\n",
        "    # model = DecisionTree(max_depth=7)\n",
        "    t0 = datetime.now()\n",
        "    model.fit(Xtrain, Ytrain)\n",
        "    print(\"Training time:\", (datetime.now() - t0))\n",
        "\n",
        "    t0 = datetime.now()\n",
        "    print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
        "    print(\"Time to compute train accuracy:\", (datetime.now() - t0))\n",
        "\n",
        "    t0 = datetime.now()\n",
        "    print(\"Test accuracy:\", model.score(Xtest, Ytest))\n",
        "    print(\"Time to compute test accuracy:\", (datetime.now() - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in and transforming data...\n",
            "depth: 1\n",
            "depth: 2\n",
            "depth: 3\n",
            "depth: 4\n",
            "depth: 4\n",
            "depth: 5\n",
            "depth: 5\n",
            "depth: 3\n",
            "depth: 4\n",
            "depth: 4\n",
            "depth: 2\n",
            "depth: 3\n",
            "depth: 4\n",
            "depth: 4\n",
            "depth: 3\n",
            "depth: 4\n",
            "depth: 4\n",
            "Training time: 0:00:10.087493\n",
            "Train accuracy: 1.0\n",
            "Time to compute train accuracy: 0:00:00.004948\n",
            "Test accuracy: 0.9895387541607228\n",
            "Time to compute test accuracy: 0:00:00.004835\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}